# 🧠 Machine Learning Cheatsheet 

A concise and beginner-friendly **Machine Learning Cheatsheet** covering key concepts, algorithms, equations, and code snippets in Python. Perfect for quick revision, interview prep, and academic reference.

## 📋 What's Inside?

- 📚 **Supervised Learning**
  - Linear Regression
  - Logistic Regression
  - Decision Trees
  - K-Nearest Neighbors (KNN)
  - Naive Bayes
  - Support Vector Machine (SVM)

- 📊 **Unsupervised Learning**
  - K-Means Clustering
  - Hierarchical Clustering
  - Principal Component Analysis (PCA)

- ⚙️ **Model Evaluation**
  - Confusion Matrix
  - Accuracy, Precision, Recall, F1-Score
  - ROC-AUC

- 🧹 **Data Preprocessing**
  - Handling Missing Data
  - Feature Scaling (Normalization & Standardization)
  - Encoding Categorical Data

- 🧮 **Math & Stats Basics**
  - Probability
  - Bayes Theorem
  - Cost Functions
  - Gradient Descent

- 🧰 **Cheat Code Snippets (Python)**
  - Using `scikit-learn`, `pandas`, `numpy`, `matplotlib`

## 💡 Why Use This?

- Quickly recall ML formulas and syntax
- Reference during coding or studying
- Compact, structured, and beginner-friendly
- Ideal for students, developers, and interview prep

## 🧰 Folder Structure
```
  Machine-Learning/
├── Notes/
│   ├── Pandas.doc
│   ├── Numpy.docs
│   ├── Matplotlib.docs
│   ├── Scikit.docs
├── Cleanin Data/
│   ├── 1_Finding_missing values.ipynb
│   ├── 2_handling_null_values.ipynb
│   ├── 3_Filling_missing_values.ipynb
|   ├── 4_fillingvalues_sckit_learn.ipynb
|   ├── 5_OneHotEncoding.ipynb
|   ├── 6_Label_Encoding.ipynb
|   ├── 7_Ordinal_Encoding.ipynb
├── Outliers/
│   ├── 8_Finding_Outliers.ipynb
│   ├── 9_Removeoutlier_IQR_Method.ipynb
│   ├── 10_Removeoutlier_Z_score.ipynb
├── Feature Scaling/
│   ├── 11_FeatureScaling_Standardization.ipynb
│   ├── 12_FeatureScaling_Normalization(min-max).ipynb
├── Outliers/
│   ├── 8_Finding_Outliers.ipynb
│   ├── 9_Removeoutlier_IQR_Method.ipynb
│   ├── 10_Removeoutlier_Z_score.ipynb
├── Handling Duplicate Values/
│   ├── 13_Remove_Duplicated_Values.ipynb
│   ├── 16_Replace&Change_DataType.ipynb
├── Function Transformer/
│   ├── 14_Function_Transformer.ipynb
├── Feature Selection/
│   ├── 15_Feature_Selection(back & forward).ipynb
├── Supervised ML/
│   ├── 20_Train_Test_Split_data.ipynb
│   ├── Classification
|        ├── 22_Classification_LogisticR_OnSingle_Input.ipynb
|        ├── 23_Classification_LogisticR_Multiple_Input.ipynb
|        ├── 24_1_Classification_LinearRegression_model.ipynb
|        ├── 24_2_Classification_Multiple_Input.ipynb
|        ├── 25_BinaryClassification_Polynomialinput.ipynb
|        ├── 26_Multiclass_Classification.ipynb
|        ├── 27_Confusion_Matrix.ipynb
|        ├── 28_Data_Imbalance.ipynb
|        ├── 29_Imblearn_module.ipynb
|        ├── 31_DecisionTree_Classification-Copy1.ipynb
|        ├── 32_DecisionTree_Classification_Pruning.ipynb
│   ├── Regression
├        |── 17_Regression(LinearRegression).ipynb
|        ├── 18_Multiple_Regression.ipynb
|        ├── 19_Polynomial_Regression.ipynb
|        ├── 21_Regularization.ipynb
├── Decision Tree/
│   ├── 31_DecisionTree_Classification-Copy1.ipynb
│   ├── 32_DecisionTree_Classification_Pruning.ipynb
│   ├── 33_DecisionTree_Regression.ipynb
├── KNN/
│   ├── 334_KNN_Classification.ipynb
│   ├── 35_KNN_Regression.ipynb
├── SVM/
│   ├── 36_SVM_Classification.ipynb
│   ├── 37_SVM_Regression.ipynb
├── Hyper and Model Parameter/
│   ├── 38_Hyperparamaters.ipynb
├── Cross Validation/
│   ├── 39_Cross_Validation.ipynb
├── UnSupervised ML/
|   ├── Association/
├         |── 44_Aprior_algorithm.ipynb
|         ├── 45_FP_Growth_Algorithm.ipynb
|    ├── Clustering/
├         |── 40_K_means_Clustering.ipynb
|         ├── 41_Agglomarative_Heirarchical_Clustering.ipynb
|         ├── 42_DBSCAN_Clustering.ipynb
|         ├── 43_Silhouette_Score.ipynb
├── Ensemble Learning/
│   ├── 46_Vote_Average(Classification).ipynb
│   ├── 47_VotingAverage(Regression).ipynb
│   ├── 48_Bagging(Classification).ipynb
|   ├── 49_Bagging(Regression).ipynb
└── README.md

```
